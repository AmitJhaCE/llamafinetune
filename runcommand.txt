# Basemodel
# Change the ckpt_dir and tokenizer_path args to the basemodel directory
torchrun --nproc_per_node 1 scripts/test_generate_basemodel.py \
    --ckpt_dir "/workspace/Meta-Llama-3.1-8B/" \
    --tokenizer_path "/workspace/Meta-Llama-3.1-8B/tokenizer.model" \
    --max_seq_len 512 --max_batch_size 4


# Instruct Model
# Change the ckpt_dir and tokenizer_path args to the basemodel directory
torchrun --nproc_per_node 1 scripts/test_chat_instruct.py \
    --ckpt_dir "/workspace/Meta-Llama-3.1-8B-Instruct/" \
    --tokenizer_path "/workspace/Meta-Llama-3.1-8B-Instruct/tokenizer.model" \
    --max_seq_len 2048 --max_batch_size 1


torchrun --nproc_per_node 1 scripts/cricket_prompt.py \
    --ckpt_dir "/workspace/Meta-Llama-3.1-8B-Instruct/" \
    --tokenizer_path "/workspace/Meta-Llama-3.1-8B-Instruct/tokenizer.model" \
    --max_seq_len 2048 --max_batch_size 1